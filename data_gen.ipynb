{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # Open a file in read mode ('r')\n",
    "# file_path = 'shortterm-files.txt'\n",
    "# download_directory = 'data/'\n",
    "\n",
    "# os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "# try:\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             # Process each line here\n",
    "#             print(\"Downloading...\",line.strip())  # Strip removes trailing newline character\n",
    "#             url=line.strip()\n",
    "#             # Extract the filename from the URL\n",
    "#             filename = os.path.join(download_directory, os.path.basename(url))\n",
    "#             # Download the file\n",
    "#             wget.download(url, out=filename)\n",
    "#             # Unzip the file\n",
    "#             with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#                 zip_ref.extractall(download_directory)\n",
    "            \n",
    "#             # Remove the ZIP file (optional, if you want to keep it, remove this line)\n",
    "#             os.remove(filename)\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"The file '{file_path}' does not exist.\")\n",
    "# except IOError:\n",
    "#     print(f\"An error occurred while reading the file '{file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fr=Dict(\"Delta\"=>(0.5,4),\n",
    "#         \"Theta\"=>(4,8),\n",
    "#         \"Alpha\"=>(8,12),\n",
    "#         \"Beta\"=>(12,35),\n",
    "#         \"Lgamma\"=>(35,80),\n",
    "#         \"Hgamma\"=>(80,150)\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "\n",
    "sampling_rate=512;\n",
    "bin_size=10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfreqz, sosfilt, hilbert\n",
    "def feq_filter(signal, fstart, fstop, fs):\n",
    "    # Create second-order sections (SOS) for the filter\n",
    "    nyquist = 0.5 * fs\n",
    "    low = fstart / nyquist\n",
    "    high = fstop / nyquist\n",
    "    sos = butter(4, [low, high], btype='band', output='sos')\n",
    "    \n",
    "    # Apply filter to the signal\n",
    "    filtered_signal = sosfilt(sos, signal)\n",
    "    \n",
    "    # Hilbert Transformation\n",
    "    complex_signal = hilbert(filtered_signal)\n",
    "    amplitude_signal = np.abs(complex_signal)\n",
    "    \n",
    "    return amplitude_signal\n",
    "\n",
    "def amp_en(alldata, start, stop, bin_size=bin_size):\n",
    "    number_of_datapoints, number_of_channels = alldata.shape\n",
    "    \n",
    "    # Filtering all the channels\n",
    "    filtered = np.empty((number_of_datapoints, number_of_channels))\n",
    "    for i in range(number_of_channels):\n",
    "        filtered[:, i] = feq_filter(alldata[:, i], start, stop, fs=sampling_rate)\n",
    "    \n",
    "    en = np.empty(number_of_datapoints)\n",
    "    \n",
    "    # Calculating Entropies across channels\n",
    "    for t in range(number_of_datapoints):\n",
    "        hist, bin_edges = np.histogram(filtered[t, :], bins=np.arange(min(filtered[t, :]), max(filtered[t, :]) + bin_size, bin_size))\n",
    "        pmf = hist / np.sum(hist)\n",
    "        pmf = pmf[pmf > 0]\n",
    "        en[t] = -np.sum(pmf * np.log2(pmf))\n",
    "    \n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io\n",
    "# import glob\n",
    "# import numpy as np\n",
    "\n",
    "# #Modify the Path here acording to the download location\n",
    "# data_path=\"/home/sapta/Documents/\"\n",
    "\n",
    "\n",
    "\n",
    "# for patid in range(1,17):\n",
    "#     mat_files = glob.glob(os.path.join(data_path+\"ID\"+str(patid), '*.mat'))\n",
    "#     no_of_seizures = len(mat_files)\n",
    "#     #print(\"No of seizures: \", no_of_seizures)\n",
    "#     Slength=[];no_of_electrodes=[];\n",
    "\n",
    "#     for i in range(1,no_of_seizures+1):\n",
    "#         filename = os.path.join(data_path, \"ID\"+str(patid)+\"/Sz\"+str(i)+\".mat\")\n",
    "#         mat=scipy.io.loadmat(filename)\n",
    "#         data=np.array(mat.get('EEG'))\n",
    "\n",
    "#         #Sampling rate is 512Hz and each seizure preceded and succeeded by a 3 mins long segment\n",
    "#         sez_length=(np.shape(data)[0]/sampling_rate) - (2*3*60) #in seconds\n",
    "#         no_elec=np.shape(data)[1]\n",
    "        \n",
    "#         Slength.append(sez_length) #in seconds\n",
    "#         no_of_electrodes.append(no_elec)\n",
    "        \n",
    "        \n",
    "#     print(\"PatID:\",patid,\" Electrodes \",np.mean(no_of_electrodes),\"/\",np.std(no_of_electrodes),\" Szs \",no_of_seizures,\" Max/Min \",np.max(Slength),\"/\",np.min(Slength))   \n",
    "    \n",
    "\n",
    "# time=np.arange(1,np.shape(data)[0],sampling_rate,) / (sampling_rate*60) # time_window in Mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.io\n",
    "# import os\n",
    "\n",
    "\n",
    "# data_path=\"/home/sapta/Documents/\"\n",
    "# patid=1; szid=1;\n",
    "\n",
    "\n",
    "# filename = os.path.join(data_path, \"ID\"+str(patid)+\"/Sz\"+str(szid)+\".mat\")\n",
    "# mat=scipy.io.loadmat(filename)\n",
    "# data=np.array(mat.get('EEG'))\n",
    "\n",
    "# sez_length=(np.shape(data)[0]/sampling_rate) - (2*3*60) #in seconds\n",
    "# no_elec=np.shape(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m output_events[\u001b[39m'\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(amp_en(data, \u001b[39m12\u001b[39m,\u001b[39m35\u001b[39m))\n\u001b[1;32m     37\u001b[0m output_events[\u001b[39m'\u001b[39m\u001b[39mlgamma\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(amp_en(data, \u001b[39m35\u001b[39m,\u001b[39m80\u001b[39m))\n\u001b[0;32m---> 39\u001b[0m output_events[\u001b[39m'\u001b[39m\u001b[39mhgamma\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(amp_en(data, \u001b[39m80\u001b[39m,\u001b[39m150\u001b[39m))\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mamp_en\u001b[0;34m(alldata, start, stop, bin_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m# Calculating Entropies across channels\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_datapoints):\n\u001b[0;32m---> 30\u001b[0m     hist, bin_edges \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhistogram(filtered[t, :], bins\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marange(\u001b[39mmin\u001b[39m(filtered[t, :]), \u001b[39mmax\u001b[39m(filtered[t, :]) \u001b[39m+\u001b[39m bin_size, bin_size))\n\u001b[1;32m     31\u001b[0m     pmf \u001b[39m=\u001b[39m hist \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(hist)\n\u001b[1;32m     32\u001b[0m     pmf \u001b[39m=\u001b[39m pmf[pmf \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ampEN/lib/python3.11/site-packages/numpy/lib/histograms.py:879\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, density, weights)\u001b[0m\n\u001b[1;32m    876\u001b[0m             bin_index \u001b[39m=\u001b[39m _search_sorted_inclusive(sa, bin_edges)\n\u001b[1;32m    877\u001b[0m             cum_n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cw[bin_index]\n\u001b[0;32m--> 879\u001b[0m     n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiff(cum_n)\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m density:\n\u001b[1;32m    882\u001b[0m     db \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39mdiff(bin_edges), \u001b[39mfloat\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ampEN/lib/python3.11/site-packages/numpy/lib/function_base.py:1448\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[1;32m   1446\u001b[0m op \u001b[39m=\u001b[39m not_equal \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_ \u001b[39melse\u001b[39;00m subtract\n\u001b[1;32m   1447\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m-> 1448\u001b[0m     a \u001b[39m=\u001b[39m op(a[slice1], a[slice2])\n\u001b[1;32m   1450\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_events={'fileID':[],'sez_len':[],'elec_no':[],'delta':[],'theta':[],'alpha':[],'beta':[],'lgamma':[],'hgamma':[]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Modify the Path here acording to the download location\n",
    "data_path=\"/home/sapta/Documents/\"\n",
    "\n",
    "\n",
    "\n",
    "for patid in range(1,17):\n",
    "    mat_files = glob.glob(os.path.join(data_path+\"ID\"+str(patid), '*.mat'))\n",
    "    no_of_seizures = len(mat_files)\n",
    "    #print(\"No of seizures: \", no_of_seizures)\n",
    "    #Slength=[];no_of_electrodes=[];\n",
    "\n",
    "    for i in range(1,no_of_seizures+1):\n",
    "        filename = os.path.join(data_path, \"ID\"+str(patid)+\"/Sz\"+str(i)+\".mat\")\n",
    "        mat=scipy.io.loadmat(filename)\n",
    "        data=np.array(mat.get('EEG'))\n",
    "\n",
    "        #Sampling rate is 512Hz and each seizure preceded and succeeded by a 3 mins long segment\n",
    "        sez_length=(np.shape(data)[0]/sampling_rate) - (2*3*60) #in seconds\n",
    "        no_elec=np.shape(data)[1]\n",
    "        \n",
    "        # Slength.append(sez_length) #in seconds\n",
    "        # no_of_electrodes.append(no_elec)\n",
    "        \n",
    "        \n",
    "        output_events['fileID'].append(\"p\"+str(patid)+\"s\"+str(i))#Recorded in seconds\n",
    "        output_events['sez_len'].append(sez_length)#Recorded in seconds\n",
    "        output_events['elec_no'].append(no_elec)\n",
    "        output_events['delta'].append(amp_en(data, 0.5,4))\n",
    "        output_events['theta'].append(amp_en(data, 4,8))\n",
    "        output_events['alpha'].append(amp_en(data, 8,12))\n",
    "        output_events['beta'].append(amp_en(data, 12,35))\n",
    "        output_events['lgamma'].append(amp_en(data, 35,80))\n",
    "        \n",
    "        output_events['hgamma'].append(amp_en(data, 80,150))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "out=pd.DataFrame.from_dict(output_events)\n",
    "out.to_json(\"../../Code_4/all_data_Swiss-Short.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = out.to_json(orient=\"records\")\n",
    "# parsed = json.loads(result)\n",
    "# with open(\"../../Code_3/all_data_Swiss-Short.json\", \"w\") as write_file:\n",
    "#         json.dump(parsed, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ampEN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
